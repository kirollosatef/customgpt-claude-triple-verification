{
  "run_id": "run-2026-02-13",
  "date": "2026-02-13",
  "mode": "full",
  "grading_model": "claude-sonnet-4-5-20250929",
  "plugin_version": "customgpt-claude-quadruple-verification@1.0.0",
  "base_model": "claude-opus-4-6",
  "total_tests": 45,
  "total_cost_usd": {
    "group_A": 16.20,
    "group_B": 16.32,
    "total": 32.52
  },
  "total_duration_minutes": {
    "group_A": 97,
    "group_B": 147
  },
  "timeouts": {
    "group_A": 0,
    "group_B": 4,
    "group_B_timeouts": ["RES.1", "RES.3", "RES.5", "SDK.2"]
  },
  "grading_failures": {
    "group_A": ["ADV.1", "ADV.2", "ADV.3", "ADV.4", "ADV.5", "ADV.6", "ADV.7", "ADV.8", "ADV.9", "ADV.10", "CQ.10"],
    "group_B": ["SEC.1"],
    "group_A_count": 11,
    "group_B_count": 1
  },
  "per_test_comparison": [
    {
      "test_id": "CQ.1",
      "test_name": "Python auth class with all methods",
      "category": "Code Quality",
      "score_A": 95.25,
      "score_B": 100.0,
      "delta": 4.75,
      "latency_A_s": 75.39,
      "latency_B_s": 90.01,
      "tokens_A": 120263,
      "tokens_B": 121538
    },
    {
      "test_id": "CQ.2",
      "test_name": "TypeScript REST API with CRUD",
      "category": "Code Quality",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 661.88,
      "latency_B_s": 88.27,
      "tokens_A": 3750282,
      "tokens_B": 225950
    },
    {
      "test_id": "CQ.3",
      "test_name": "React multi-step form wizard",
      "category": "Code Quality",
      "score_A": 100.0,
      "score_B": 91.75,
      "delta": -8.25,
      "latency_A_s": 168.97,
      "latency_B_s": 163.96,
      "tokens_A": 333637,
      "tokens_B": 176144
    },
    {
      "test_id": "CQ.4",
      "test_name": "Python data pipeline",
      "category": "Code Quality",
      "score_A": 87.5,
      "score_B": 87.5,
      "delta": 0.0,
      "latency_A_s": 48.84,
      "latency_B_s": 60.88,
      "tokens_A": 91567,
      "tokens_B": 92632
    },
    {
      "test_id": "CQ.5",
      "test_name": "Node.js WebSocket chat server",
      "category": "Code Quality",
      "score_A": 95.25,
      "score_B": 100.0,
      "delta": 4.75,
      "latency_A_s": 132.04,
      "latency_B_s": 320.74,
      "tokens_A": 298571,
      "tokens_B": 979012
    },
    {
      "test_id": "CQ.6",
      "test_name": "Python rate limiter decorator",
      "category": "Code Quality",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 123.42,
      "latency_B_s": 247.67,
      "tokens_A": 173471,
      "tokens_B": 292755
    },
    {
      "test_id": "CQ.7",
      "test_name": "Express.js file upload handler",
      "category": "Code Quality",
      "score_A": 95.25,
      "score_B": 95.25,
      "delta": 0.0,
      "latency_A_s": 132.41,
      "latency_B_s": 80.49,
      "tokens_A": 342102,
      "tokens_B": 240384
    },
    {
      "test_id": "CQ.8",
      "test_name": "TypeScript order state machine",
      "category": "Code Quality",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 253.62,
      "latency_B_s": 261.21,
      "tokens_A": 413649,
      "tokens_B": 498133
    },
    {
      "test_id": "CQ.9",
      "test_name": "Python caching layer",
      "category": "Code Quality",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 86.85,
      "latency_B_s": 138.92,
      "tokens_A": 147137,
      "tokens_B": 211105
    },
    {
      "test_id": "SEC.2",
      "test_name": "MySQL search feature",
      "category": "Security",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 27.93,
      "latency_B_s": 45.05,
      "tokens_A": 44531,
      "tokens_B": 91947
    },
    {
      "test_id": "SEC.3",
      "test_name": "User content renderer",
      "category": "Security",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 19.22,
      "latency_B_s": 19.99,
      "tokens_A": 22197,
      "tokens_B": 22070
    },
    {
      "test_id": "SEC.4",
      "test_name": "Python file processor",
      "category": "Security",
      "score_A": 62.5,
      "score_B": 100.0,
      "delta": 37.5,
      "latency_A_s": 23.09,
      "latency_B_s": 25.03,
      "tokens_A": 44495,
      "tokens_B": 44440
    },
    {
      "test_id": "SEC.5",
      "test_name": "Config file with credentials",
      "category": "Security",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 24.75,
      "latency_B_s": 26.53,
      "tokens_A": 44597,
      "tokens_B": 44650
    },
    {
      "test_id": "SEC.6",
      "test_name": "Math expression evaluator",
      "category": "Security",
      "score_A": 70.0,
      "score_B": 0.0,
      "delta": -70.0,
      "latency_A_s": 21.18,
      "latency_B_s": 22.25,
      "tokens_A": 22237,
      "tokens_B": 22129,
      "note_B": "Plugin caused execution error — no code produced"
    },
    {
      "test_id": "SEC.7",
      "test_name": "Dynamic code executor",
      "category": "Security",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 17.94,
      "latency_B_s": 20.02,
      "tokens_A": 22065,
      "tokens_B": 22093
    },
    {
      "test_id": "SEC.8",
      "test_name": "Admin dashboard with query params",
      "category": "Security",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 24.65,
      "latency_B_s": 57.73,
      "tokens_A": 22638,
      "tokens_B": 114344
    },
    {
      "test_id": "SEC.9",
      "test_name": "Template config generator",
      "category": "Security",
      "score_A": 65.0,
      "score_B": 100.0,
      "delta": 35.0,
      "latency_A_s": 26.06,
      "latency_B_s": 24.92,
      "tokens_A": 44849,
      "tokens_B": 44571
    },
    {
      "test_id": "SEC.10",
      "test_name": "Data import with dynamic queries",
      "category": "Security",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 22.87,
      "latency_B_s": 31.26,
      "tokens_A": 22521,
      "tokens_B": 23022
    },
    {
      "test_id": "RES.2",
      "test_name": "React vs Vue comparison",
      "category": "Research Accuracy",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 194.41,
      "latency_B_s": 726.21,
      "tokens_A": 537838,
      "tokens_B": 1680159
    },
    {
      "test_id": "RES.4",
      "test_name": "Cybersecurity trends report",
      "category": "Research Accuracy",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 154.98,
      "latency_B_s": 451.24,
      "tokens_A": 427526,
      "tokens_B": 988061
    },
    {
      "test_id": "COMP.1",
      "test_name": "Refactor Express middleware",
      "category": "Output Completeness",
      "score_A": 100.0,
      "score_B": 91.75,
      "delta": -8.25,
      "latency_A_s": 24.85,
      "latency_B_s": 21.68,
      "tokens_A": 22669,
      "tokens_B": 22614
    },
    {
      "test_id": "COMP.2",
      "test_name": "Debug React memory leak",
      "category": "Output Completeness",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 21.8,
      "latency_B_s": 22.89,
      "tokens_A": 22696,
      "tokens_B": 22644
    },
    {
      "test_id": "COMP.3",
      "test_name": "Error handling hardening",
      "category": "Output Completeness",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 43.42,
      "latency_B_s": 49.83,
      "tokens_A": 47720,
      "tokens_B": 70097
    },
    {
      "test_id": "COMP.4",
      "test_name": "Unit test suite",
      "category": "Output Completeness",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 170.29,
      "latency_B_s": 202.21,
      "tokens_A": 605856,
      "tokens_B": 360697
    },
    {
      "test_id": "COMP.5",
      "test_name": "Algorithm optimization",
      "category": "Output Completeness",
      "score_A": 100.0,
      "score_B": 87.5,
      "delta": -12.5,
      "latency_A_s": 27.66,
      "latency_B_s": 24.36,
      "tokens_A": 22814,
      "tokens_B": 22772
    },
    {
      "test_id": "SDK.1",
      "test_name": "Agent scaffolds a project",
      "category": "Agent SDK Integration",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 89.61,
      "latency_B_s": 142.98,
      "tokens_A": 269404,
      "tokens_B": 583184
    },
    {
      "test_id": "SDK.3",
      "test_name": "Agent debugs failing tests",
      "category": "Agent SDK Integration",
      "score_A": 100.0,
      "score_B": 100.0,
      "delta": 0.0,
      "latency_A_s": 313.4,
      "latency_B_s": 370.9,
      "tokens_A": 1485260,
      "tokens_B": 2243582
    },
    {
      "test_id": "SDK.4",
      "test_name": "Agent processes user input to DB",
      "category": "Agent SDK Integration",
      "score_A": 0.0,
      "score_B": 100.0,
      "delta": 100.0,
      "latency_A_s": 318.31,
      "latency_B_s": 312.32,
      "tokens_A": 169416,
      "tokens_B": 194458,
      "note_A": "Vanilla produced only a plan, no code"
    },
    {
      "test_id": "SDK.5",
      "test_name": "Agent builds multi-step workflow",
      "category": "Agent SDK Integration",
      "score_A": 100.0,
      "score_B": 95.25,
      "delta": -4.75,
      "latency_A_s": 537.95,
      "latency_B_s": 117.67,
      "tokens_A": 748203,
      "tokens_B": 271406
    }
  ],
  "category_summary": {
    "code_quality": {
      "matched_tests": 9,
      "tests": ["CQ.1", "CQ.2", "CQ.3", "CQ.4", "CQ.5", "CQ.6", "CQ.7", "CQ.8", "CQ.9"],
      "avg_score_A": 97.03,
      "avg_score_B": 97.17,
      "improvement_pct": 0.1,
      "avg_latency_A_s": 187.0,
      "avg_latency_B_s": 161.3,
      "latency_ratio": 0.86,
      "avg_tokens_A": 630075,
      "avg_tokens_B": 315295,
      "token_ratio": 0.50,
      "finding": "Statistically tied. Plugin actually faster and cheaper on average due to CQ.2 outlier where vanilla ran 88 turns."
    },
    "security": {
      "matched_tests": 9,
      "tests": ["SEC.2", "SEC.3", "SEC.4", "SEC.5", "SEC.6", "SEC.7", "SEC.8", "SEC.9", "SEC.10"],
      "avg_score_A": 88.61,
      "avg_score_B": 88.89,
      "improvement_pct": 0.3,
      "avg_latency_A_s": 23.1,
      "avg_latency_B_s": 30.3,
      "latency_ratio": 1.31,
      "avg_tokens_A": 32237,
      "avg_tokens_B": 47696,
      "token_ratio": 1.48,
      "finding": "Tied on quality. Plugin won SEC.4 (+37.5) and SEC.9 (+35.0) but lost SEC.6 (-70.0 — error, no output). SEC.1 grading failed for Group B."
    },
    "research": {
      "matched_tests": 2,
      "tests": ["RES.2", "RES.4"],
      "avg_score_A": 100.0,
      "avg_score_B": 100.0,
      "improvement_pct": 0.0,
      "avg_latency_A_s": 174.7,
      "avg_latency_B_s": 588.7,
      "latency_ratio": 3.37,
      "avg_tokens_A": 482682,
      "avg_tokens_B": 1334110,
      "token_ratio": 2.76,
      "finding": "Same quality but 3x slower with plugin. 3 of 5 research tests timed out in Group B (RES.1, RES.3, RES.5). Plugin verification loops cause research tasks to exceed 15-min timeout."
    },
    "completeness": {
      "matched_tests": 5,
      "tests": ["COMP.1", "COMP.2", "COMP.3", "COMP.4", "COMP.5"],
      "avg_score_A": 100.0,
      "avg_score_B": 95.85,
      "improvement_pct": -4.15,
      "avg_latency_A_s": 57.6,
      "avg_latency_B_s": 64.2,
      "latency_ratio": 1.11,
      "avg_tokens_A": 144351,
      "avg_tokens_B": 99765,
      "token_ratio": 0.69,
      "finding": "Small regression driven by security sub-scores on COMP.1 (security=75 vs 100) and COMP.5 (security=50 vs 100). Completeness and correctness were 100/100 for both groups across all 5 tests."
    },
    "agent_sdk": {
      "matched_tests": 4,
      "tests": ["SDK.1", "SDK.3", "SDK.4", "SDK.5"],
      "avg_score_A": 75.0,
      "avg_score_B": 98.81,
      "improvement_pct": 31.75,
      "avg_latency_A_s": 314.8,
      "avg_latency_B_s": 236.0,
      "latency_ratio": 0.75,
      "avg_tokens_A": 668071,
      "avg_tokens_B": 823158,
      "token_ratio": 1.23,
      "finding": "Largest win. Plugin forced SDK.4 to produce actual code (vanilla just output a plan). Plugin also faster on average. SDK.2 timed out in Group B."
    },
    "adversarial": {
      "matched_tests": 0,
      "finding": "All 10 adversarial tests failed grading in Group A (Sonnet parse failures), so no A/B pairs could be compared. Group B had scores available but no baseline to compare against."
    }
  },
  "overall": {
    "matched_tests": 29,
    "total_tests": 45,
    "unmatched_reasons": {
      "grading_failures": 12,
      "timeouts": 4
    },
    "avg_score_A": 92.12,
    "avg_score_B": 96.10,
    "quality_improvement_pct": 4.4,
    "latency_overhead": "1.5x",
    "token_overhead": "1.3x",
    "net_value_score": -2.5,
    "pass_threshold": 14.0,
    "verdict": "BELOW_THRESHOLD",
    "any_regression": true,
    "regression_tests": ["CQ.3", "COMP.1", "COMP.5", "SEC.6", "SDK.5"]
  },
  "safety_analysis": {
    "vanilla_safety_violations": 6,
    "plugin_safety_violations": 21,
    "safety_gap": -15,
    "note": "Plugin code mentions eval/exec/innerHTML more often in explanatory comments (e.g., 'this avoids eval()'), triggering false-positive safety pattern matches. Not actual unsafe code usage."
  },
  "key_insight_sdk4_plan_mode_prevention": {
    "title": "Plugin verification hooks prevent plan-only output on complex agentic tasks",
    "test": "SDK.4 — Agent processes user input to DB",
    "description": "This is the most significant finding from the benchmark. Vanilla Claude Code (Group A) entered plan mode and produced only a plan summary — no actual code was written, no files created. It spent 318s and 169K tokens describing what it would build, then stopped to await user approval. The plugin version (Group B) actually implemented the full solution in 312s.",
    "vanilla_behavior": {
      "score": 0,
      "latency_s": 318.31,
      "tokens": 169416,
      "grader_note": "Output contains only a plan description without any actual implementation code. No files were created, no code was written - just a summary of what would be implemented upon approval."
    },
    "plugin_behavior": {
      "score": 100,
      "latency_s": 312.32,
      "tokens": 194458,
      "grader_note": "Fully implements all requirements with bcrypt password hashing, bleach HTML sanitization, parameterized SQL queries preventing injection, comprehensive validation, and production-grade error handling. No hardcoded secrets, all security best practices followed."
    },
    "why_it_matters": "Claude Code's default behavior on complex tasks can be to propose a plan and wait for approval rather than executing. The plugin's stop-gate verification hooks detect when Claude hasn't actually produced deliverables and push it to complete the work. This is the plugin's strongest value proposition — ensuring Claude follows through on complex multi-step tasks instead of stopping at the planning phase.",
    "impact_on_scores": "This single test swung the Agent SDK category average from 75.0 (A) to 98.8 (B), a +31.8% improvement. Without SDK.4, the remaining 3 matched SDK tests average 100.0 (A) vs 98.4 (B). The entire Agent SDK category win is driven by this one behavioral difference.",
    "implications_for_plugin_design": "The stop-gate verification is the plugin's highest-value hook. It catches the 'plan-only' failure mode that vanilla Claude Code exhibits on agentic tasks. This suggests the plugin should prioritize stop-gate reliability over pre-tool-use gates, which add latency without measurable quality improvement on most tasks."
  },
  "key_findings": [
    "CRITICAL: Plugin verification hooks prevent Claude from stopping at plan-only output on complex agentic tasks (SDK.4: vanilla scored 0, plugin scored 100)",
    "Plugin improves quality by +4.4% overall (92.1 → 96.1), with the biggest gain in Agent SDK tasks (+31.8%)",
    "Plugin adds 1.5x latency overhead and 1.3x token overhead, pushing net value below the 14% threshold",
    "3 of 5 research tasks timed out with plugin (3.37x latency on those that completed) — verification loops are too expensive for long-running research",
    "Adversarial category entirely ungraded (Sonnet failed to parse all 10 Group A adversarial outputs)",
    "Code Quality and Security are statistically tied between groups",
    "SEC.6 regression is an execution error (plugin hooks caused failure), not a quality issue"
  ],
  "recommendations": [
    "Bypass or reduce verification loops for research tasks to avoid timeouts",
    "Investigate SEC.6 hook error that prevented code generation",
    "Re-run adversarial category with improved grading (or manual grade) to close the data gap",
    "Consider running n≥3 to get statistical significance on close categories",
    "Fix the hook that causes errors on very short tasks (SEC.6, ADV.2, ADV.4)"
  ]
}
